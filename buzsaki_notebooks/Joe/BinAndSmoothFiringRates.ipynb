{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load necessary libraries and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../../swdb_2019_tools')\n",
    "import spikeutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.ndimage.filters import gaussian_filter1d\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "from allensdk.brain_observatory.ecephys.ecephys_project_cache import EcephysProjectCache\n",
    "from allensdk.brain_observatory.ecephys import ecephys_session\n",
    "%matplotlib inline\n",
    "\n",
    "# fix slow autocomplete\n",
    "%config Completer.use_jedi = False\n",
    "\n",
    "import platform\n",
    "platstring = platform.platform()\n",
    "\n",
    "if 'Darwin' in platstring:\n",
    "    # OS X \n",
    "    data_root = \"/Volumes/Brain2019/\"\n",
    "elif 'Windows'  in platstring:\n",
    "    # Windows (replace with the drive letter of USB drive)\n",
    "    data_root = \"E:/\"\n",
    "elif ('amzn1' in platstring):\n",
    "    # then on AWS\n",
    "    data_root = \"/data/\"\n",
    "else:\n",
    "    # then your own linux platform\n",
    "    # EDIT location where you mounted hard drive\n",
    "    data_root = \"/media/$USERNAME/Brain2019/\"\n",
    "\n",
    "manifest_path = os.path.join(data_root, \"dynamic-brain-workshop/visual_coding_neuropixels/2019/manifest.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Session with associated units, spike times, etc.\n",
    "> #### *areas*: select desired brain region acronyms to extract sessions that have cells in those regions\n",
    "> #### *session*: select desired session\n",
    "> #### Note: If you would like any further session/unit/spike sub-selection, do it in this chunk to feed into the next chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = EcephysProjectCache.fixed(manifest=manifest_path)\n",
    "sessions = cache.get_sessions()\n",
    "\n",
    "areas = ['CA','DG']\n",
    "area_sessions = [] # Adds all the sessions that have the desired areas (designated above)\n",
    "for i in np.arange(len(sessions.structure_acronyms)):\n",
    "    sessionid = sessions.structure_acronyms.index[i]\n",
    "    if any(elem in sessions.structure_acronyms[sessionid] for elem in areas):\n",
    "        area_sessions.append(sessionid)\n",
    "\n",
    "session = cache.get_session_data(area_sessions[0])\n",
    "units = session.units\n",
    "spike_times = session.spike_times\n",
    "sampling_rate = 30000 # The sampling rate is very stable across probes\n",
    "\n",
    "# Just CA units\n",
    "CA_units = units[units.structure_acronym =='CA']\n",
    "CA_spikes = {unit : spike_times[unit] for unit in CA_units.index}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bin spikes by a specified sampling rate\n",
    "> #### *unitsForBinning*: which units to use (should be in the form of a DF as __units__ above)\n",
    "> #### *spikesForBinning*: which spikes to use (should be in the form of a dictionary as __spikes__ above)\n",
    "> #### *startTime & endTime*: the desired range of time in seconds\n",
    "> #### *binsize*: the desired sampling rate after binning (in Hz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unitsForBinning = CA_units\n",
    "spikesForBinning = CA_spikes\n",
    "unitNames = np.asarray([n for n in spikesForBinning.keys()])\n",
    "toBin = [sp for sp in spikesForBinning.values()]\n",
    "startTime = 0\n",
    "endTime = 9000\n",
    "binsize = 1000\n",
    "binned = spikeutils.spiketimes_to_2D_rates(toBin, startime=startTime, stoptime=endTime, binsize=binsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creates DataFrame of RSUs and FSUs from above units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cellType = []\n",
    "for i in unitNames:\n",
    "    if unitsForBinning[unitsForBinning.index.values == i].waveform_duration.values[0] < 0.4:\n",
    "        cellType = np.append(cellType, 'FSU')\n",
    "    else:\n",
    "        cellType = np.append(cellType, 'RSU')\n",
    "cellTypeDF = pd.DataFrame(data={'CellType': cellType}, index=unitNames.astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smooth firing rates with a gaussian filter\n",
    "> #### Set *sigma*: the amount by which you would like the spikes to be smoothed\n",
    "> #### Note: I would play around with the sigma value to get the amount of smoothing you desire for your desired application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib notebook\n",
    "# Remove above line if running in jupyter-lab\n",
    "sigma = 10\n",
    "smoothed = np.zeros(binned.shape)\n",
    "for cell in range(binned.shape[0]):\n",
    "    smoothed[cell,:] = gaussian_filter1d(binned[cell,:], sigma=sigma) # Smoothed firing rate signal\n",
    "\n",
    "# Plot before and after smoothing\n",
    "fig, ax = plt.subplots(nrows=2,ncols=1,figsize=(18,10), sharex=True, sharey=True)\n",
    "for i in range(5):\n",
    "    maxVal = np.max([smoothed.max(), binned.max()])\n",
    "    ax[0].plot(binned[i,:] + i*maxVal/20)\n",
    "    ax[0].set_title('Before Smoothing', fontsize=20)\n",
    "    ax[1].plot(smoothed[i,:] + i*maxVal/20)\n",
    "    ax[1].set_title('After Smoothing', fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize firing rates to max of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "normalized = smoothed.copy()\n",
    "for cell in range(smoothed.shape[0]):\n",
    "    maxVal = np.max(smoothed[cell,:])\n",
    "    if maxVal != 0:\n",
    "        normalized[cell,:] = smoothed[cell,:] / maxVal\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "for cell in range(10):\n",
    "    plt.plot(normalized[cell,:]+cell*2)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.imshow(normalized, aspect='auto', cmap='viridis')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save binned and smoothed firing rates to CSV\n",
    "> #### Insert __description__ as a string for use in output file name\n",
    "> #### Insert which data to output in __traces__:\n",
    "- #### *binned*: Firing rates that have been binned but not smoothed\n",
    "- #### *smoothed*: Firing rates that have been both binned and smoothed\n",
    "- #### *normalized*: Firing rates that have been binned, smoothed, and normalized to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = \"CA_units\"\n",
    "traces = normalized\n",
    "unitsToOutput = pd.concat([cellTypeDF, pd.DataFrame(normalized, index=unitNames.astype(int))], axis=1)\n",
    "unitsToOutput.to_csv(('./' + description + '_session_' + str(area_sessions[0]) + \"_binned\" +\n",
    "                      str(startTime) + \"to\" + str(endTime) + \"Secs\" + str(binsize) + \"binsize\" + '_GaussianSmoothed_sigma' + str(sigma) + '.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
